{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equal-sustainability",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technical-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import internal modules\n",
    "import os.path\n",
    "import joblib\n",
    "from typing import List, Set, Dict, TypedDict, Tuple, Optional\n",
    "\n",
    "# Import 3rd party modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-peripheral",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlimited-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_db</th>\n",
       "      <th>machine_type</th>\n",
       "      <th>model_id</th>\n",
       "      <th>sound</th>\n",
       "      <th>sound_path</th>\n",
       "      <th>target</th>\n",
       "      <th>spect_mean</th>\n",
       "      <th>spect_min</th>\n",
       "      <th>spect_max</th>\n",
       "      <th>spect_std</th>\n",
       "      <th>...</th>\n",
       "      <th>zero_crossing_rate_max</th>\n",
       "      <th>zero_crossing_rate_std</th>\n",
       "      <th>d_harmonic_mean</th>\n",
       "      <th>d_harmonic_min</th>\n",
       "      <th>d_harmonic_max</th>\n",
       "      <th>d_harmonic_std</th>\n",
       "      <th>d_percussive_mean</th>\n",
       "      <th>d_percussive_min</th>\n",
       "      <th>d_percussive_max</th>\n",
       "      <th>d_percussive_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6</td>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "      <td>00000000.wav</td>\n",
       "      <td>assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.107133</td>\n",
       "      <td>1.922508e-11</td>\n",
       "      <td>8.000317</td>\n",
       "      <td>0.286640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.059173</td>\n",
       "      <td>1.413419e-12</td>\n",
       "      <td>7.861723</td>\n",
       "      <td>0.217199</td>\n",
       "      <td>0.047960</td>\n",
       "      <td>1.447360e-11</td>\n",
       "      <td>2.427006</td>\n",
       "      <td>0.102428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6</td>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "      <td>00000001.wav</td>\n",
       "      <td>assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.091550</td>\n",
       "      <td>1.239772e-10</td>\n",
       "      <td>11.825641</td>\n",
       "      <td>0.306949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.051675</td>\n",
       "      <td>1.856747e-13</td>\n",
       "      <td>11.707416</td>\n",
       "      <td>0.261016</td>\n",
       "      <td>0.039876</td>\n",
       "      <td>7.817087e-11</td>\n",
       "      <td>2.639281</td>\n",
       "      <td>0.086876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6</td>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "      <td>00000002.wav</td>\n",
       "      <td>assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.114412</td>\n",
       "      <td>2.546376e-10</td>\n",
       "      <td>8.061798</td>\n",
       "      <td>0.300529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.061442</td>\n",
       "      <td>5.859085e-13</td>\n",
       "      <td>7.840732</td>\n",
       "      <td>0.220184</td>\n",
       "      <td>0.052971</td>\n",
       "      <td>7.954731e-11</td>\n",
       "      <td>2.856351</td>\n",
       "      <td>0.114448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6</td>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "      <td>00000003.wav</td>\n",
       "      <td>assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.108589</td>\n",
       "      <td>6.224236e-11</td>\n",
       "      <td>7.651740</td>\n",
       "      <td>0.277428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.064017</td>\n",
       "      <td>1.636899e-13</td>\n",
       "      <td>7.523073</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>2.057399e-11</td>\n",
       "      <td>1.847202</td>\n",
       "      <td>0.077006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6</td>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "      <td>00000004.wav</td>\n",
       "      <td>assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.107343</td>\n",
       "      <td>9.855214e-12</td>\n",
       "      <td>7.804570</td>\n",
       "      <td>0.287012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>1.400486e-13</td>\n",
       "      <td>7.756195</td>\n",
       "      <td>0.248836</td>\n",
       "      <td>0.043042</td>\n",
       "      <td>4.824911e-12</td>\n",
       "      <td>2.022621</td>\n",
       "      <td>0.079337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_db machine_type  model_id         sound  \\\n",
       "0        -6       slider         0  00000000.wav   \n",
       "1        -6       slider         0  00000001.wav   \n",
       "2        -6       slider         0  00000002.wav   \n",
       "3        -6       slider         0  00000003.wav   \n",
       "4        -6       slider         0  00000004.wav   \n",
       "\n",
       "                                          sound_path    target  spect_mean  \\\n",
       "0  assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...  abnormal    0.107133   \n",
       "1  assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...  abnormal    0.091550   \n",
       "2  assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...  abnormal    0.114412   \n",
       "3  assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...  abnormal    0.108589   \n",
       "4  assets\\sounds\\-6_dB_slider\\slider\\id_00\\abnorm...  abnormal    0.107343   \n",
       "\n",
       "      spect_min  spect_max  spect_std  ...  zero_crossing_rate_max  \\\n",
       "0  1.922508e-11   8.000317   0.286640  ...                0.125488   \n",
       "1  1.239772e-10  11.825641   0.306949  ...                0.122559   \n",
       "2  2.546376e-10   8.061798   0.300529  ...                0.107422   \n",
       "3  6.224236e-11   7.651740   0.277428  ...                0.125488   \n",
       "4  9.855214e-12   7.804570   0.287012  ...                0.119141   \n",
       "\n",
       "   zero_crossing_rate_std  d_harmonic_mean  d_harmonic_min  d_harmonic_max  \\\n",
       "0                0.015289         0.059173    1.413419e-12        7.861723   \n",
       "1                0.022209         0.051675    1.856747e-13       11.707416   \n",
       "2                0.013853         0.061442    5.859085e-13        7.840732   \n",
       "3                0.012602         0.064017    1.636899e-13        7.523073   \n",
       "4                0.010417         0.064301    1.400486e-13        7.756195   \n",
       "\n",
       "   d_harmonic_std  d_percussive_mean  d_percussive_min  d_percussive_max  \\\n",
       "0        0.217199           0.047960      1.447360e-11          2.427006   \n",
       "1        0.261016           0.039876      7.817087e-11          2.639281   \n",
       "2        0.220184           0.052971      7.954731e-11          2.856351   \n",
       "3        0.240022           0.044573      2.057399e-11          1.847202   \n",
       "4        0.248836           0.043042      4.824911e-12          2.022621   \n",
       "\n",
       "   d_percussive_std  \n",
       "0          0.102428  \n",
       "1          0.086876  \n",
       "2          0.114448  \n",
       "3          0.077006  \n",
       "4          0.079337  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"assets\",\"data\",\"thread_csv_all.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-midnight",
   "metadata": {},
   "source": [
    "## Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-westminster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rotary-knock",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spect_mean', 'spect_min', 'spect_max', 'spect_std', 'mel_spect_mean', 'mel_spect_min', 'mel_spect_max', 'mel_spect_std', 'chroma_mean', 'chroma_min', 'chroma_max', 'chroma_std', 'chroma_cq_mean', 'chroma_cq_min', 'chroma_cq_max', 'chroma_cq_std', 'chroma_cens_mean', 'chroma_cens_min', 'chroma_cens_max', 'chroma_cens_std', 'mfcc_mean', 'mfcc_min', 'mfcc_max', 'mfcc_std', 'rms_mean', 'rms_min', 'rms_max', 'rms_std', 'cent_mean', 'cent_min', 'cent_max', 'cent_std', 'spec_bw_mean', 'spec_bw_min', 'spec_bw_max', 'spec_bw_std', 'contrast_mean', 'contrast_min', 'contrast_max', 'contrast_std', 'flatness_mean', 'flatness_min', 'flatness_max', 'flatness_std', 'roll_off_mean', 'roll_off_min', 'roll_off_max', 'roll_off_std', 'tonnetz_mean', 'tonnetz_min', 'tonnetz_max', 'tonnetz_std', 'zero_crossing_rate_mean', 'zero_crossing_rate_min', 'zero_crossing_rate_max', 'zero_crossing_rate_std', 'd_harmonic_mean', 'd_harmonic_min', 'd_harmonic_max', 'd_harmonic_std', 'd_percussive_mean', 'd_percussive_min', 'd_percussive_max', 'd_percussive_std']\n"
     ]
    }
   ],
   "source": [
    "## select numeric columns\n",
    "selected_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "## drop noise_db and model_id columns\n",
    "selected_cols.remove(\"noise_db\")\n",
    "selected_cols.remove(\"model_id\")\n",
    "\n",
    "print(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "experienced-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features X and target variable y\n",
    "X = df[selected_cols]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-superior",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "computational-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (40542, 64)   - y_train: (40542,)\n",
      "X_val:   (8109, 64)    - y_train: (8109,)\n",
      "X_test:  (5406, 64)    - y_train: (5406,)\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation and test sets\n",
    "## Specify fractions of entire of dataset\n",
    "train_fraction = 0.75\n",
    "validation_fraction = 0.15\n",
    "test_fraction = 0.10\n",
    "\n",
    "## Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=1 - train_fraction,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y\n",
    "                                                   )\n",
    "\n",
    "## Split the test sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size=test_fraction/(test_fraction + validation_fraction),\n",
    "                                                random_state=42,\n",
    "                                                stratify=y_test\n",
    "                                               )\n",
    "\n",
    "print(f\"X_train: {X_train.shape}   - y_train: {y_train.shape}\")\n",
    "print(f\"X_val:   {X_val.shape}    - y_train: {y_val.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}    - y_train: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature union\n",
    "# features = []\n",
    "# features.append(('pca', PCA(n_components=3)))\n",
    "# features.append(('select_best', SelectKBest(k=6)))\n",
    "# feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "# estimators = []\n",
    "# estimators.append(('feature_union', feature_union))\n",
    "# estimators.append(('logistic', LogisticRegression()))\n",
    "# model = Pipeline(estimators)\n",
    "# # evaluate pipeline\n",
    "# seed = 7\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(model, X, Y, cv=kfold)\n",
    "# print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-nevada",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bridal-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create pipelines\n",
    "pipe_random_forest = make_pipeline(RandomForestClassifier(random_state=5))\n",
    "pipe_decision_tree = make_pipeline(DecisionTreeClassifier(random_state=5))\n",
    "pipe_svm = make_pipeline(SVC(random_state=5))\n",
    "pipe_logistic_regression = make_pipeline(LogisticRegression(random_state=5))\n",
    "\n",
    "# 2. GridSearchCV for each pipeline: to train models with different parameters\n",
    "# and get the best models (for each pipeline) with the best parameters\n",
    "\n",
    "## 2.1 Define grid search parameters\n",
    "grid_params_random_forest = {\n",
    "    'randomforestclassifier__n_estimators': [90, 100, 110],\n",
    "    'randomforestclassifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "#                               'clf__max_depth': param_range,\n",
    "#                               'clf__min_samples_split': param_range[1:]}]\n",
    "grid_params_decision_tree = {\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_params_svm = {\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__C': [9, 10]\n",
    "}\n",
    "\n",
    "grid_params_logistic_regression = {\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [1.0, 0.5],\n",
    "    'logisticregression__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "## 2.2 Instantiate grid searches\n",
    "### set n_jobs to -1 to use all processors\n",
    "n_jobs: int = 3\n",
    "\n",
    "grid_random_forest = GridSearchCV(\n",
    "    estimator=pipe_random_forest,\n",
    "    param_grid=grid_params_random_forest,\n",
    "    scoring='recall',\n",
    "    cv=10,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "grid_decision_tree = GridSearchCV(\n",
    "    estimator=pipe_decision_tree,\n",
    "    param_grid=grid_params_decision_tree,\n",
    "    scoring='recall',\n",
    "    cv=10,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    estimator=pipe_svm,\n",
    "    param_grid=grid_params_svm,\n",
    "    scoring='recall',\n",
    "    cv=10,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "grid_random_logistic_regression = GridSearchCV(\n",
    "    estimator=pipe_logistic_regression,\n",
    "    param_grid=grid_params_logistic_regression,\n",
    "    scoring='recall',\n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "## 2.3 Create dict of grids\n",
    "grids: Dict[str, GridSearchCV] = {\n",
    "    \"random_forest\": grid_random_forest,\n",
    "    \"decision_tree\": grid_decision_tree,\n",
    "    \"svm\": grid_svm,\n",
    "    \"logistic_regression\": grid_random_logistic_regression\n",
    "}\n",
    "\n",
    "# 2.4 Keep track of the best accuracy score\n",
    "best_recall = 0.0\n",
    "best_model = None\n",
    "best_model_name = \"\"    \n",
    "    \n",
    "## 2.4 Fit the grids to the training set\n",
    "for grid_name, grid in grids.items():\n",
    "    print(grid_name)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f'best params: {grid.best_params_}')\n",
    "    print(f'best training recall: {grid.best_score_}')\n",
    "    \n",
    "    # predict on test set with best parameters\n",
    "    y_pred = grid.predict(X_test)\n",
    "    recall_score = recall_score(y_test, y_pred)\n",
    "    print(f'accuracy on test set with best parameters: {recall_score}')\n",
    "    \n",
    "    # Update the best model\n",
    "    if recall_score > best_recall:\n",
    "        best_recall = recall_score\n",
    "        best_model = grid\n",
    "        best_model_name = grid_name\n",
    "\n",
    "print(f\"Model with best recall on test set: {grid_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.5 Save the best grid search pipeline to pkl file\n",
    "filepath = os.path.join(\"assets\",\"data\",\"best_model.joblib\")\n",
    "joblib.dump(best_model, filepath, compress=1)\n",
    "print(f\"Best model ({best_model_name}) is saved\")\n",
    "\n",
    "# ## 2.5 Save the best grid search pipeline to sav file\n",
    "# filepath = os.path.join(\"assets\",\"data\",\"best_model.sav\")\n",
    "# pickle.dump(best_model, open(filepath, 'wb'))\n",
    "\n",
    "## Load the model\n",
    "result = joblib.load(filepath) \n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = pickle.load(open(filepath, 'rb'))\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "print(result)\n",
    "print(classification_report(y_test, loaded_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "category_transformer = make_pipeline(OneHotEncoder())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
