{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "czech-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check xgboost version\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "different-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_audio_f_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54057, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complimentary-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[:, 5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secondary-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"target\"].replace({\"abnormal\": \"1\", \"normal\": \"0\"}, inplace=True)\n",
    "df_test = df_test.astype({\"target\": int})\n",
    "y = df_test['target']\n",
    "df_test = df_test.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joined-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70651, 14) (70651,)\n",
      "(17663, 14) (17663,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(df_test, y)\n",
    "\n",
    "# Split dataframe into random train and test subsets\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_over,\n",
    "    y_over,\n",
    "    test_size=0.2,\n",
    "    random_state=200\n",
    ")\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "manual-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43245, 14) (43245,)\n",
      "(10812, 14) (10812,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into random train and test subsets\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    df_test,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=200\n",
    ")\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thermal-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRFClassifier(n_estimators=100, subsample=0.9, colsample_bynode=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "novel-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRFClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=0.2, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                importance_type='gain', interaction_constraints='',\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "                num_parallel_tree=100, objective='binary:logistic',\n",
       "                random_state=0, reg_alpha=0, scale_pos_weight=1, subsample=0.9,\n",
       "                tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "connected-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hindu-genealogy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_xg = round(model.score(X_test, Y_test) * 100, 2)\n",
    "acc_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acquired-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.74      8861\n",
      "           1       0.82      0.49      0.61      8802\n",
      "\n",
      "    accuracy                           0.69     17663\n",
      "   macro avg       0.73      0.69      0.68     17663\n",
      "weighted avg       0.73      0.69      0.68     17663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "obvious-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-james",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
